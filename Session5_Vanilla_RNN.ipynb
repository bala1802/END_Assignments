{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Session5_Vanilla_RNN.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyPUoi6sBnSk08hvmXpIii8f",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/bala1802/END_Assignments/blob/main/Session5_Vanilla_RNN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4yCLK5NVluIv"
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-haPH8nbmPyD"
      },
      "source": [
        "For Time Series -\n",
        "\n",
        "* Forecasting - many-to-many or many-to-one\n",
        "\n",
        "* Classification - many-to-one\n",
        "\n",
        "\n",
        "For NLP -\n",
        "* Text Classification: many-to-one\n",
        "\n",
        "* Text Generation: many-to-many\n",
        "\n",
        "* Machine Translation: many-to-many\n",
        "\n",
        "* Named Entity Recognition: many-to-many\n",
        "\n",
        "* Image Captioning: one-to-many"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eKgDpoVcmIij"
      },
      "source": [
        "data = torch.Tensor([1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20])"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WtxzCUoyoMqK",
        "outputId": "12be0792-1833-4a85-dbfa-c4932f034b8a"
      },
      "source": [
        "print(\"Data: \", data.shape, \"\\n\\n\", data)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Data:  torch.Size([20]) \n",
            "\n",
            " tensor([ 1.,  2.,  3.,  4.,  5.,  6.,  7.,  8.,  9., 10., 11., 12., 13., 14.,\n",
            "        15., 16., 17., 18., 19., 20.])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PPIWTwgYoXTN"
      },
      "source": [
        "* From here, the input data is \n",
        "\n",
        "[1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20]\n",
        "\n",
        "* Dividing the input data into 4 batches of sequence length = 5\n",
        "\n",
        "\n",
        "[[1, 2, 3, 4, 5],\n",
        "\n",
        "[6, 7, 8, 9, 10],\n",
        "\n",
        "[11, 12, 13, 14, 15],\n",
        "\n",
        "[16, 17, 18, 19, 20]]\n",
        "\n",
        "* Batch Size = 4\n",
        "* Sequence Length = 5\n",
        "* Input Size = 1 (Since, only one dimension)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XmryneaOwGJx"
      },
      "source": [
        "**Input:**\n",
        "\n",
        "torch.rnn has 2 inputs: `input` and `h_0`\n",
        "\n",
        "`input` size will be of `(sequence_length, batch, input_size)` in our example, `(5, 4, 1)`\n",
        "\n",
        "`h_0` initial hidden state of the network. size will be of `(num_layers * num_directions, batch, input_size)` in our example, `(num_layers * num_directions, 4, 1)`\n",
        "\n",
        "**Output:**\n",
        "\n",
        "torch.rnn has 2 outputs: `output` and `hidden` (`h_n`)\n",
        "\n",
        "`output` size will be of `(sequence_length, batch, num_directions * hidden_size)` \n",
        "\n",
        "`h_n` size will be of `(num_layers * num_directions, batch, hidden_size)`\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PFXVwLd1oPQm"
      },
      "source": [
        "# Number of features used as input. (Number of columns)\n",
        "INPUT_SIZE = 1\n",
        "\n",
        "# Number of previous time stamps taken into account.\n",
        "SEQ_LENGTH = 5\n",
        "\n",
        "# Number of features in last hidden state ie. number of output timesteps to predict\n",
        "HIDDEN_SIZE = 2\n",
        "\n",
        "# Number of stacked rnn layers.\n",
        "NUM_LAYERS = 1\n",
        "\n",
        "# We have total of 20 rows in our input. \n",
        "# We divide the input into 4 batches where each batch has only 1\n",
        "# row. Each row corresponds to a sequence of length 5. \n",
        "BATCH_SIZE = 4"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "chGDhtV2y2bG"
      },
      "source": [
        "**Input:**\n",
        "\n",
        "torch.rnn has 2 inputs: `input` and `h_0`\n",
        "\n",
        "`input` size will be of `(sequence_length, batch, input_size)` in our example, `(5, 4, 1)`\n",
        "\n",
        "`h_0` initial hidden state of the network. size will be of `(num_layers * num_directions, batch, input_size)` in our example, `(1 * num_directions, 4, 1)`\n",
        "\n",
        "**Output:**\n",
        "\n",
        "torch.rnn has 2 outputs: `output` and `hidden` (`h_n`)\n",
        "\n",
        "`output` size will be of `(sequence_length, batch, num_directions * hidden_size)` in our example `(5, 4, num_directions * 2)`\n",
        "\n",
        "`h_n` size will be of `(num_layers * num_directions, batch, hidden_size)` in our example `(1 * num_directions, 4, 2)`\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zKBVQJ6NpbOO"
      },
      "source": [
        "#initializing the RNN\n",
        "rnn = nn.RNN(input_size=INPUT_SIZE, hidden_size=HIDDEN_SIZE, num_layers = 1, batch_first=True)\n",
        "\n",
        "# input size : (batch, seq_len, input_size)\n",
        "inputs = data.view(BATCH_SIZE, SEQ_LENGTH, INPUT_SIZE)\n",
        "\n",
        "# out shape = (batch, seq_len, num_directions * hidden_size)\n",
        "# h_n shape  = (num_layers * num_directions, batch, hidden_size)\n",
        "out, h_n = rnn(inputs)"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TYwkSq_x0xSD",
        "outputId": "5df0d954-b05d-452d-d3c6-11582fde6e4d"
      },
      "source": [
        "print('Input: ', inputs.shape, '\\n', inputs) #(4,5,1) = (batch_size, seq_len, input_size)\n",
        "print('\\nOutput: ', out.shape, '\\n', out) #(4, 5, 2) - (batch_size, seq_len, num_directions * hidden_size) num_directions = 1, hidden_size = 2\n",
        "print('\\nHidden: ', h_n.shape, '\\n', h_n) #(1, 4, 2) - (num_layers * num_directions, batch, hidden_size) num_layers = 1, num_directions = 1"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Input:  torch.Size([4, 5, 1]) \n",
            " tensor([[[ 1.],\n",
            "         [ 2.],\n",
            "         [ 3.],\n",
            "         [ 4.],\n",
            "         [ 5.]],\n",
            "\n",
            "        [[ 6.],\n",
            "         [ 7.],\n",
            "         [ 8.],\n",
            "         [ 9.],\n",
            "         [10.]],\n",
            "\n",
            "        [[11.],\n",
            "         [12.],\n",
            "         [13.],\n",
            "         [14.],\n",
            "         [15.]],\n",
            "\n",
            "        [[16.],\n",
            "         [17.],\n",
            "         [18.],\n",
            "         [19.],\n",
            "         [20.]]])\n",
            "\n",
            "Output:  torch.Size([4, 5, 2]) \n",
            " tensor([[[ 0.3609, -0.6926],\n",
            "         [ 0.7274, -0.5721],\n",
            "         [ 0.8379, -0.7582],\n",
            "         [ 0.9022, -0.7705],\n",
            "         [ 0.9325, -0.8169]],\n",
            "\n",
            "        [[ 0.8268, -0.8828],\n",
            "         [ 0.9639, -0.8497],\n",
            "         [ 0.9763, -0.8941],\n",
            "         [ 0.9834, -0.9095],\n",
            "         [ 0.9881, -0.9253]],\n",
            "\n",
            "        [[ 0.9624, -0.9582],\n",
            "         [ 0.9938, -0.9466],\n",
            "         [ 0.9956, -0.9584],\n",
            "         [ 0.9968, -0.9658],\n",
            "         [ 0.9977, -0.9721]],\n",
            "\n",
            "        [[ 0.9923, -0.9855],\n",
            "         [ 0.9988, -0.9812],\n",
            "         [ 0.9991, -0.9849],\n",
            "         [ 0.9994, -0.9878],\n",
            "         [ 0.9995, -0.9901]]], grad_fn=<TransposeBackward1>)\n",
            "\n",
            "Hidden:  torch.Size([1, 4, 2]) \n",
            " tensor([[[ 0.9325, -0.8169],\n",
            "         [ 0.9881, -0.9253],\n",
            "         [ 0.9977, -0.9721],\n",
            "         [ 0.9995, -0.9901]]], grad_fn=<StackBackward>)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ShcnHhxs4v_k"
      },
      "source": [
        "In the output above, notice the last row in each batch of `out` is present in `h_n`.\n",
        "\n",
        "* `out` is the output value at all time-steps of the last RNN layer for each batch.\n",
        "\n",
        "* `h_n` is the hidden value at the last time-step of all RNN layers for each batch."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "auG-JGMc5pi-"
      },
      "source": [
        "**Stacked RNN**\n",
        "\n",
        "`num_layers = 3`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wYiZreqN4WWN"
      },
      "source": [
        "# Initialize the RNN.\n",
        "rnn = nn.RNN(input_size=INPUT_SIZE, hidden_size=HIDDEN_SIZE, num_layers = 3, batch_first=True)\n",
        "\n",
        "# input size : (batch_size , seq_len, input_size)\n",
        "inputs = data.view(BATCH_SIZE, SEQ_LENGTH, INPUT_SIZE)\n",
        "\n",
        "# out shape = (batch, seq_len, num_directions * hidden_size)\n",
        "# h_n shape  = (num_layers * num_directions, batch, hidden_size)\n",
        "out, h_n = rnn(inputs)"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JkMg3p3o6Jqj",
        "outputId": "003616d7-24eb-4af6-aa16-b6d0ada4d214"
      },
      "source": [
        "print('Input: ', inputs.shape, '\\n', inputs) #(4,5,1) = (batch_size, seq_len, input_size)\n",
        "print('\\nOutput: ', out.shape, '\\n', out) #(4, 5, 2) - (batch_size, seq_len, num_directions * hidden_size) num_directions = 1, hidden_size = 2\n",
        "print('\\nHidden: ', h_n.shape, '\\n', h_n) #(3, 4, 2) - (num_layers * num_directions, batch, hidden_size) num_layers = 3, num_directions = 1"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Input:  torch.Size([4, 5, 1]) \n",
            " tensor([[[ 1.],\n",
            "         [ 2.],\n",
            "         [ 3.],\n",
            "         [ 4.],\n",
            "         [ 5.]],\n",
            "\n",
            "        [[ 6.],\n",
            "         [ 7.],\n",
            "         [ 8.],\n",
            "         [ 9.],\n",
            "         [10.]],\n",
            "\n",
            "        [[11.],\n",
            "         [12.],\n",
            "         [13.],\n",
            "         [14.],\n",
            "         [15.]],\n",
            "\n",
            "        [[16.],\n",
            "         [17.],\n",
            "         [18.],\n",
            "         [19.],\n",
            "         [20.]]])\n",
            "\n",
            "Output:  torch.Size([4, 5, 2]) \n",
            " tensor([[[0.6081, 0.4663],\n",
            "         [0.7592, 0.6240],\n",
            "         [0.7163, 0.6406],\n",
            "         [0.7470, 0.6262],\n",
            "         [0.7036, 0.6339]],\n",
            "\n",
            "        [[0.5675, 0.4616],\n",
            "         [0.7137, 0.6033],\n",
            "         [0.6372, 0.6187],\n",
            "         [0.6968, 0.5945],\n",
            "         [0.6605, 0.6170]],\n",
            "\n",
            "        [[0.5442, 0.4587],\n",
            "         [0.6968, 0.5927],\n",
            "         [0.6246, 0.6134],\n",
            "         [0.6896, 0.5898],\n",
            "         [0.6557, 0.6147]],\n",
            "\n",
            "        [[0.5416, 0.4584],\n",
            "         [0.6950, 0.5915],\n",
            "         [0.6233, 0.6128],\n",
            "         [0.6888, 0.5893],\n",
            "         [0.6552, 0.6145]]], grad_fn=<TransposeBackward1>)\n",
            "\n",
            "Hidden:  torch.Size([3, 4, 2]) \n",
            " tensor([[[-0.9932,  0.7362],\n",
            "         [-1.0000,  0.9726],\n",
            "         [-1.0000,  0.9972],\n",
            "         [-1.0000,  0.9997]],\n",
            "\n",
            "        [[-0.0409, -0.6184],\n",
            "         [ 0.0368, -0.5720],\n",
            "         [ 0.0444, -0.5675],\n",
            "         [ 0.0451, -0.5671]],\n",
            "\n",
            "        [[ 0.7036,  0.6339],\n",
            "         [ 0.6605,  0.6170],\n",
            "         [ 0.6557,  0.6147],\n",
            "         [ 0.6552,  0.6145]]], grad_fn=<StackBackward>)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kEdDsAO06W4B"
      },
      "source": [
        "**Bidirectional RNN:**\n",
        "\n",
        "`bidirectional=True`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OmyNeZH56Pdr"
      },
      "source": [
        "rnn = nn.RNN(input_size=INPUT_SIZE, hidden_size=HIDDEN_SIZE, batch_first=True, num_layers = 1, bidirectional = True)\n",
        "\n",
        "# input size : (batch_size , seq_len, input_size)\n",
        "inputs = data.view(BATCH_SIZE, SEQ_LENGTH, INPUT_SIZE)\n",
        "\n",
        "# out shape = (batch, seq_len, num_directions * hidden_size)\n",
        "# h_n shape  = (num_layers * num_directions, batch, hidden_size)\n",
        "out, h_n = rnn(inputs)"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AgbCMXzb6wR5",
        "outputId": "7ca6f4f5-4f43-4559-8aa9-523d7931919e"
      },
      "source": [
        "print('Input: ', inputs.shape, '\\n', inputs) #(4,5,1) = (batch_size, seq_len, input_size)\n",
        "print('\\nOutput: ', out.shape, '\\n', out) #(4, 5, 4) - (batch_size, seq_len, num_directions * hidden_size) num_directions = 2, hidden_size = 2\n",
        "print('\\nHidden: ', h_n.shape, '\\n', h_n) #(2, 4, 2) - (num_layers * num_directions, batch, hidden_size) num_layers = 1, num_directions = 2"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Input:  torch.Size([4, 5, 1]) \n",
            " tensor([[[ 1.],\n",
            "         [ 2.],\n",
            "         [ 3.],\n",
            "         [ 4.],\n",
            "         [ 5.]],\n",
            "\n",
            "        [[ 6.],\n",
            "         [ 7.],\n",
            "         [ 8.],\n",
            "         [ 9.],\n",
            "         [10.]],\n",
            "\n",
            "        [[11.],\n",
            "         [12.],\n",
            "         [13.],\n",
            "         [14.],\n",
            "         [15.]],\n",
            "\n",
            "        [[16.],\n",
            "         [17.],\n",
            "         [18.],\n",
            "         [19.],\n",
            "         [20.]]])\n",
            "\n",
            "Output:  torch.Size([4, 5, 4]) \n",
            " tensor([[[ 0.0276, -0.4332, -0.2255,  0.8560],\n",
            "         [-0.1846,  0.1208, -0.5242,  0.8499],\n",
            "         [ 0.1757,  0.6307, -0.7622,  0.8552],\n",
            "         [ 0.1578,  0.7798, -0.9021,  0.8696],\n",
            "         [ 0.2214,  0.9213, -0.9709,  0.9170]],\n",
            "\n",
            "        [[-0.0211,  0.9810, -0.9857,  0.8987],\n",
            "         [ 0.3852,  0.9925, -0.9947,  0.9121],\n",
            "         [ 0.1423,  0.9961, -0.9981,  0.9238],\n",
            "         [ 0.2815,  0.9990, -0.9993,  0.9345],\n",
            "         [ 0.1901,  0.9996, -0.9998,  0.9589]],\n",
            "\n",
            "        [[-0.0698,  0.9999, -0.9999,  0.9505],\n",
            "         [ 0.3769,  1.0000, -1.0000,  0.9572],\n",
            "         [ 0.1026,  1.0000, -1.0000,  0.9629],\n",
            "         [ 0.2612,  1.0000, -1.0000,  0.9681],\n",
            "         [ 0.1557,  1.0000, -1.0000,  0.9799]],\n",
            "\n",
            "        [[-0.1182,  1.0000, -1.0000,  0.9760],\n",
            "         [ 0.3613,  1.0000, -1.0000,  0.9792],\n",
            "         [ 0.0640,  1.0000, -1.0000,  0.9820],\n",
            "         [ 0.2385,  1.0000, -1.0000,  0.9845],\n",
            "         [ 0.1220,  1.0000, -1.0000,  0.9902]]], grad_fn=<TransposeBackward1>)\n",
            "\n",
            "Hidden:  torch.Size([2, 4, 2]) \n",
            " tensor([[[ 0.2214,  0.9213],\n",
            "         [ 0.1901,  0.9996],\n",
            "         [ 0.1557,  1.0000],\n",
            "         [ 0.1220,  1.0000]],\n",
            "\n",
            "        [[-0.2255,  0.8560],\n",
            "         [-0.9857,  0.8987],\n",
            "         [-0.9999,  0.9505],\n",
            "         [-1.0000,  0.9760]]], grad_fn=<StackBackward>)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mRQ3mPDe690d"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}